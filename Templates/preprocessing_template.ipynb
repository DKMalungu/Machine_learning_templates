{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter One: Data Preprocessing Tamplates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imporint Core LIbraies\n",
    "    Libraries are tool that facilitated the proformace pf some specif tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Its contains mathematical tools \n",
    "import matplotlib.pyplot as plt # Its contains that are helpful for drawing graphs\n",
    "import pandas as pd # It contains tools that imports and manages datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importng the Dataset Into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Text data inform of CSV\n",
    "path = 'Absolute/file/path/to/the/data_set.cv'\n",
    "attributes = ['columns'.'names','in','a','list']\n",
    "index = 'index_column_name(ID)'\n",
    "dataset = pd.read_csv(path,index_col=index, names=attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Filling Missing Values\n",
    "    Data is usually incomplete and has many inconsistenies it important to remove this inconsitenies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Determing the colunms with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum() # It will display a count af all mising values per colunm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Filling Missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are tFour staregies for filling missing values:\n",
    "    # 1. Using a global constant to fill the missing values ('Constant')\n",
    "    # 2. Using the attribute's mean to fill the missing values ('mean')\n",
    "    # 3. Using the attribute's mode to fill the missing values ('most_frequent')\n",
    "    # 4. Using the attribute's median to fill the missing values ('median')\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_miss = SimpleImputer(missing_values='nan',strategy='one_of_the_4_in_brackets',fill_value='constant')\n",
    "dataset[['column','attribute','or','colunm','index']] = imp_miss.fit_transform(dataset[['column','attribute','or','colunm','index']])\n",
    "    #Important:\n",
    "        #fill_value is used with constatnt startegy to provide the value to use to fill the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Data Transformatiom\n",
    "    it Invovs conveting the data from one format to another to convency and improve training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Categorical Values (Lablled Data)\n",
    "    Categorical values is a variable that can take one one of limited and usually fixed number of possible values, assigned to \n",
    "    each individal to a particular group on the basis of some quantitative property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import normalize , OneHotEncoder\n",
    "cat_tran = ColumnTransformer([(\"dummy_col\", OneHotEncoder(categories=[['a'], \n",
    "                                                                      ['list'],\n",
    "                                                                      ['of'],\n",
    "                                                                      ['categoriacl'],\n",
    "                                                                      ['values'],\n",
    "                                                                      ['per colums']]), [index_of_categorical_values]),\n",
    "                              (\"norm\", Normalizer(norm='l1'), [index_of_numerical_columns_for_normalization])])\n",
    "dataset = cat_tran.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Spliting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Matrix of features and Dependent variable vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,index_of_matrix_of_feature].values\n",
    "y = dataset.iloc[:,index_of_dependent_valiable_vector].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Training dataset and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_test,y_test = train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Values:\n",
    "'''\n",
    "This are values that take a finate number of values ie: Female or Male, \n",
    "There are three aproches of dealing with categoroical values:\n",
    "1. Droping the columns with categorical values\n",
    "2. Application of LabelEncoder from sklearn where the string are represented with ordinal values.\n",
    "3. Application of OneHoteEncoder fro sklearn  this approach is great for normial values\n",
    "'''\n",
    "\n",
    "#Determining columns with categorical values\n",
    "s = (X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "print(object_cols)\n",
    "\n",
    "# Approch 1: Droping Categorical Values\n",
    "dataset_drop = Dataset.select_dtypes(exclude='object')\n",
    "\n",
    "print('New Dataset After Droping Categorical Values: ',dataset_drop)\n",
    "\n",
    "\n",
    "# Approch 2. Lablel Encoding the categorical values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode_x=LabelEncoder()\n",
    "dataset_label= X_train.copy()\n",
    "\n",
    "for cols in object_cols:\n",
    "    \n",
    "    encode_X_train = encode_x.fit_transform(X_train[cols])\n",
    "    encode_X_test = encode_x.fit_transform(X_test[cols])\n",
    "\n",
    "encode_error = score_dataset(X_train,X_test,y_train,y_test)\n",
    "print('MAE for label encoding approch:',encode_error)\n",
    "\n",
    "# Approch 3: Application of OneHoteEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "\n",
    "oh_cols_train = pd.DataFrame(one_hot_encoder.fit_transform(X_train[object_cols]))\n",
    "oh_cols_test = pd.DataFrame(one_hot_encoder.fit_transform(X_test[object_cols]))\n",
    "\n",
    "## Adding back Index removed by OneHotEncoder\n",
    "oh_cols_train.index = X_train.index\n",
    "oh_cols_test.index = X_test.index\n",
    "\n",
    "## Creating dataset of numerical columns only\n",
    "num_X_train = X_train.drop(object_cols,axis = 1)\n",
    "num_X_test = X_test.drop(object_cols,axis = 1)\n",
    "\n",
    "#Recreating the Original Datase with Numerical_colunms + OneHotEncoder_Colunms\n",
    "oh_X_train = pd.concat([num_X_train,oh_cols_train],axis=1)\n",
    "oh_X_test = pd.concat([num_X_test,oh_cols_test],axis=1)\n",
    "\n",
    "#Evaluating the Approch 3 using MAE\n",
    "error_label = score_dataset(oh_X_train,oh_X_test,y_train,y_test)\n",
    "print('MEA results for Approch 3 (OneHotEncodder): ',error_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}